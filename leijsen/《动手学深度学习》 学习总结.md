# 《动手学深度学习》 学习总结

1. 《动手学第二版》第二章：
   1. 数据操作，缺失值的处理（缺失过多删除列，缺失较少填充0或填充mean值，fillna函数），torch的tensor可以直接加某个数来使tensor各维度各值都加某个数（涉及广播机制），iloc可以对DataFrame对象取值（如：df.iloc[:, 1]表示取第一列）；线性代数中，向量与向量、矩阵与向量、矩阵与矩阵的相乘对应不同的函数（torch.dot(a, b)，mv，mm （matrix是矩阵的英文）），a.sum(axis = 1， keepdims=True)：axis表示对1维度进行降维，如果不加keepdims=True保持维度不变，1维度会直接消失
   2. 微积分链式求导法则，因为数据在神经网络的传播中，函数往往不是单一的，而是多个复合函数的 结合，此时pytorch会将梯度记录在对应变量的.grad属性中，只有设置requires_grad=True的张量才会计算，这样会节省空间。自动微分：.backward()会自动构建反向传播路径，计算相应的梯度值，step()函数自动更新每个权重值
   3. 概率，样本空间，条件概率，贝叶斯定理，全概率公式，马尔可夫链的应用；期望和方差的应用